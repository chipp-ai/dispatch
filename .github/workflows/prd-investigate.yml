name: PRD Investigation

on:
  workflow_dispatch:
    inputs:
      issue_id:
        description: "Dispatch issue ID"
        required: true
        type: string
      issue_identifier:
        description: "Human-readable identifier (e.g. DISPATCH-456)"
        required: true
        type: string
      title:
        description: "Issue title / PRD summary"
        required: true
        type: string
      description:
        description: "Full PRD or feature description (markdown)"
        required: true
        type: string
      plan_feedback:
        description: "Human feedback from a previous plan rejection (optional)"
        required: false
        type: string
      additional_context:
        description: "Additional instructions from human retry (optional)"
        required: false
        type: string
      callback_url:
        description: "Override API callback URL (for local dev tunnels)"
        required: false
        type: string
      ref:
        description: "Git ref to checkout (branch, tag, or SHA). Defaults to the workflow dispatch ref."
        required: false
        type: string

# Only one investigation per issue at a time
concurrency:
  group: prd-investigate-${{ inputs.issue_identifier }}
  cancel-in-progress: false

jobs:
  investigate:
    name: Investigate ${{ inputs.issue_identifier }}
    runs-on: ubuntu-latest
    timeout-minutes: 30

    permissions:
      contents: read
      id-token: write  # Needed for GCP Workload Identity Federation

    # SECURITY: All user-provided inputs are passed through env vars to
    # prevent command injection. They are NEVER interpolated in run: blocks.
    # See: https://github.blog/security/vulnerability-research/how-to-catch-github-actions-workflow-injections-before-attackers-do/
    env:
      ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
      DISPATCH_API_URL: ${{ inputs.callback_url || secrets.DISPATCH_API_URL }}
      DISPATCH_API_KEY: ${{ secrets.DISPATCH_API_KEY }}
      CLOUD_SQL_PASSWORD: ${{ secrets.CLOUD_SQL_PASSWORD }}
      DENO_NO_PACKAGE_JSON: "1"
      INPUT_ISSUE_ID: ${{ inputs.issue_id }}
      INPUT_ISSUE_IDENTIFIER: ${{ inputs.issue_identifier }}
      INPUT_TITLE: ${{ inputs.title }}
      INPUT_DESCRIPTION: ${{ inputs.description }}
      INPUT_PLAN_FEEDBACK: ${{ inputs.plan_feedback }}
      INPUT_ADDITIONAL_CONTEXT: ${{ inputs.additional_context }}
      GITHUB_RUN_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
      MAX_AGENT_COST_PER_RUN: ${{ vars.MAX_AGENT_COST_PER_RUN || '25' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref || github.ref_name }}
          fetch-depth: 0

      - name: Setup Deno
        uses: denoland/setup-deno@v2
        with:
          deno-version: v2.x

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install Claude Code
        run: npm install -g @anthropic-ai/claude-code

      - name: Google Auth
        uses: google-github-actions/auth@v2
        with:
          token_format: access_token
          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
          service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }}

      - name: Get GKE credentials
        uses: google-github-actions/get-gke-credentials@v2
        with:
          cluster_name: production
          location: us-central1

      - name: Start Cloud SQL Proxy
        run: |
          curl -sSL https://storage.googleapis.com/cloud-sql-connectors/cloud-sql-proxy/v2.15.1/cloud-sql-proxy.linux.amd64 -o cloud-sql-proxy
          chmod +x cloud-sql-proxy
          ./cloud-sql-proxy chippai-398019:us-central1:primary-postgres --port 5432 --quiet &
          sleep 3
          echo "Cloud SQL Proxy started on localhost:5432"

      - name: Start Loki Port-Forward
        run: |
          kubectl port-forward -n monitoring svc/loki-gateway 3100:80 &
          sleep 3
          echo "Loki port-forward started on localhost:3100"

      - name: Register MCP servers
        run: |
          # Loki MCP - uses kubectl port-forward (started above)
          claude mcp add-json loki '{"type":"stdio","command":"deno","args":["run","--allow-net","--allow-env","--allow-read","--allow-run=kubectl","tools/mcp-loki/index.ts"],"env":{"LOKI_URL":"http://localhost:3100"}}'

          # Chipp-deno production DB (read-only via Cloud SQL Proxy)
          claude mcp add-json chipp-database '{"type":"stdio","command":"deno","args":["run","--allow-net","--allow-env","--allow-read","tools/mcp-chipp-db/index.ts"],"env":{"DATABASE_URL":"postgresql://postgres:'"${CLOUD_SQL_PASSWORD}"'@127.0.0.1:5432/chipp_deno"}}'

      - name: Notify Dispatch - Investigating
        if: env.DISPATCH_API_URL != '' && env.DISPATCH_API_KEY != ''
        run: |
          TIMESTAMP=$(date -u +%Y-%m-%dT%H:%M:%SZ)

          PAYLOAD=$(jq -n \
            --arg spawn_status "running" \
            --arg spawn_run_id "$GITHUB_RUN_ID" \
            --arg spawn_started_at "$TIMESTAMP" \
            --arg agent_status "investigating" \
            --arg spawn_type "investigate" \
            '{spawn_status: $spawn_status, spawn_run_id: $spawn_run_id, spawn_started_at: $spawn_started_at, agent_status: $agent_status, spawn_type: $spawn_type}')

          curl -sf -X PATCH "${DISPATCH_API_URL}/api/issues/${INPUT_ISSUE_ID}" \
            -H "Authorization: Bearer ${DISPATCH_API_KEY}" \
            -H "Content-Type: application/json" \
            -d "$PAYLOAD" || echo "Warning: Failed to notify Dispatch (non-fatal)"

      - name: Link Run Record
        if: env.DISPATCH_API_URL != '' && env.DISPATCH_API_KEY != ''
        run: |
          LINK_PAYLOAD=$(jq -n \
            --arg github_run_id "$GITHUB_RUN_ID" \
            --arg github_run_url "$GITHUB_RUN_URL" \
            '{github_run_id: $github_run_id, github_run_url: $github_run_url}')
          curl -sf -X PATCH "${DISPATCH_API_URL}/api/issues/${INPUT_ISSUE_ID}/runs/current" \
            -H "Authorization: Bearer ${DISPATCH_API_KEY}" \
            -H "Content-Type: application/json" \
            -d "$LINK_PAYLOAD" || echo "Warning: Failed to link run record (non-fatal)"

      - name: Post Run Context
        if: env.DISPATCH_API_URL != '' && env.DISPATCH_API_KEY != ''
        run: |
          mkdir -p .scratch
          python3 -c "
          import os
          fields = []
          fields.append(('Workflow', 'prd_investigate'))
          fields.append(('Issue', os.environ.get('INPUT_ISSUE_IDENTIFIER', '')))
          fields.append(('Run', os.environ.get('GITHUB_RUN_URL', '')))
          fields.append(('Title', os.environ.get('INPUT_TITLE', '')))
          desc = os.environ.get('INPUT_DESCRIPTION', '')
          if desc:
              preview = desc[:500] + ('...' if len(desc) > 500 else '')
              fields.append(('Description', preview))
          feedback = os.environ.get('INPUT_PLAN_FEEDBACK', '')
          if feedback:
              fields.append(('Plan Feedback', feedback))
          ctx = os.environ.get('INPUT_ADDITIONAL_CONTEXT', '')
          if ctx:
              fields.append(('Additional Context', ctx))
          lines = ['=' * 60, 'RUN CONTEXT', '=' * 60]
          for label, value in fields:
              if '\n' in value:
                  lines.append(f'{label}:')
                  for line in value.split('\n')[:20]:
                      lines.append(f'  {line}')
                  if value.count('\n') > 20:
                      lines.append('  ...(truncated)')
              else:
                  lines.append(f'{label}: {value}')
          lines.append('=' * 60)
          with open('.scratch/run-context.txt', 'w') as f:
              f.write('\n'.join(lines))
          print('\n'.join(lines))
          "
          jq -n --rawfile content .scratch/run-context.txt '{content: $content}' | \
            curl -sf -X POST "${DISPATCH_API_URL}/api/issues/${INPUT_ISSUE_ID}/terminal" \
              -H "Authorization: Bearer ${DISPATCH_API_KEY}" \
              -H "Content-Type: application/json" \
              -d @- || echo "Warning: Failed to post run context (non-fatal)"

      - name: Build investigation prompt
        run: |
          mkdir -p .scratch

          # Build prompt file using jq for safe string handling (no shell interpolation of inputs)
          jq -n \
            --arg identifier "$INPUT_ISSUE_IDENTIFIER" \
            --arg title "$INPUT_TITLE" \
            --arg description "$INPUT_DESCRIPTION" \
            --arg feedback "$INPUT_PLAN_FEEDBACK" \
            --arg additional_context "$INPUT_ADDITIONAL_CONTEXT" \
            '{identifier: $identifier, title: $title, description: $description, feedback: $feedback, additional_context: $additional_context}' \
            > .scratch/prompt-data.json

          python3 -c "
          import json, sys
          d = json.load(open('.scratch/prompt-data.json'))
          feedback_section = ''
          if d['feedback']:
              feedback_section = f\"\"\"\n\nPrevious Plan Feedback (address these concerns):\n{d['feedback']}\n\"\"\"
          additional_section = ''
          if d.get('additional_context'):
              additional_section = f\"\"\"\n\nADDITIONAL CONTEXT FROM HUMAN:\n{d['additional_context']}\n\"\"\"
          prompt = f\"\"\"You are autonomously investigating a feature request / PRD for this project.
          Your goal is to explore the codebase and produce a STRUCTURED IMPLEMENTATION PLAN.
          You are READ-ONLY -- do NOT create branches, modify files, or write code.

          Issue: {d['identifier']} - {d['title']}

          Description / PRD:
          {d['description']}{feedback_section}{additional_section}

          PRODUCTION LOGS (Loki MCP):
          You have access to production logs via MCP tools. Useful for understanding current behavior:
          - loki_errors(since: \"24h\") -- recent errors across all modules
          - loki_search(pattern: \"<keyword>\", since: \"24h\") -- find related logs
          - loki_stats(since: \"24h\", groupBy: \"source\") -- overview of recent errors

          DATABASE ACCESS (Production - READ ONLY):
          You have access to the production chipp_deno database via MCP tools.
          Useful for understanding schema, data model, and current state:
          - db_query(sql: \"SELECT ...\") -- run read-only queries against production
          - db_describe_table(table: \"schema.table_name\") -- inspect table structure
          - db_list_tables() -- list all tables
          - db_find_table(pattern: \"...\") -- find tables by name
          - db_sample_rows(table: \"schema.table_name\") -- see sample data
          IMPORTANT: The database is READ-ONLY. Do NOT attempt writes.

          Instructions:
          1. Read CLAUDE.md first to understand the codebase
          2. Explore all relevant files, services, routes, components, and database schemas
          3. Check for existing patterns, utilities, and conventions
          4. Identify environment variables, secrets, or external dependencies needed
          5. Write a STRUCTURED PLAN to .scratch/plan.md with these sections:

          ## Summary
          Brief description of what will be built.

          ## Files to Create
          - path/to/new/file.ts -- purpose

          ## Files to Modify
          - path/to/existing/file.ts -- what changes and why

          ## Database Changes
          Migration SQL or \"none\"

          ## API Changes
          New or modified endpoints

          ## UI Changes
          New or modified components

          ## Dependencies
          New packages, env vars, secrets needed

          ## Testing Strategy
          How to verify the implementation works

          ## Risks
          What could go wrong, edge cases

          ## Stop Conditions
          Conditions under which the implementation agent should STOP and report a blocker:
          - List specific scenarios (missing env vars, unclear requirements, etc.)

          ## Estimated Complexity
          Simple / Medium / Complex

          6. Do NOT attempt any code changes
          7. Do NOT create branches
          8. If you cannot understand the requirements well enough to plan, write that in the plan

          MANDATORY - RUN RESULT DECLARATION:
          Before exiting, you MUST write .scratch/run-result.json with:
          {{
            \"outcome\": \"investigation_complete|blocked|needs_human_decision|failed\",
            \"summary\": \"1-2 sentence explanation\",
            \"changes_made\": false,
            \"files_changed\": [],
            \"pr_needed\": false
          }}

          - Use \"investigation_complete\" if you produced a plan successfully.
          - Use \"blocked\" if requirements are unclear and you cannot plan.
          - Use \"needs_human_decision\" if there are multiple valid approaches and a human must choose.
          - Use \"failed\" if you could not complete the investigation.
          \"\"\"
          with open('.scratch/investigation-prompt.md', 'w') as f:
              f.write(prompt)
          "

      - name: Run Investigation
        id: investigate
        run: |
          # Create stream filter for human-readable output
          cat > .scratch/stream-filter.py << 'PYEOF'
          import sys, json
          for line in sys.stdin:
              line = line.strip()
              if not line: continue
              try:
                  event = json.loads(line)
                  t = event.get("type", "")
                  if t == "assistant":
                      for c in event.get("message", {}).get("content", []):
                          if c.get("type") == "text" and c.get("text"):
                              print(c["text"], flush=True)
                          elif c.get("type") == "tool_use":
                              name = c.get("name", "unknown")
                              inp = c.get("input", {})
                              parts = [f"{k}={str(v)[:80]}" for k, v in list(inp.items())[:3]]
                              print(f"[TOOL] {name}({', '.join(parts)})", flush=True)
                  elif t == "tool_result":
                      content = event.get("content", "")
                      if isinstance(content, list):
                          content = " ".join(c.get("text", "") for c in content if isinstance(c, dict))
                      preview = str(content)[:200] + ("..." if len(str(content)) > 200 else "")
                      print(f"[RESULT] {preview}", flush=True)
                  elif t == "result":
                      print(f"\n[COMPLETED] Cost: ${event.get('total_cost_usd', 0):.2f}, Turns: {event.get('num_turns', 0)}", flush=True)
              except (json.JSONDecodeError, KeyError):
                  print(line, flush=True)
          PYEOF

          # Claude CLI buffers ALL output when stdout is not a TTY.
          # Use `script` to create a pseudo-TTY, forcing line-buffered output.
          cat > .scratch/run-claude.sh << 'RUNEOF'
          #!/bin/bash
          PROMPT=$(cat .scratch/investigation-prompt.md)
          exec claude --print --model claude-opus-4-6 --verbose --output-format stream-json --dangerously-skip-permissions --max-budget-usd "${MAX_AGENT_COST_PER_RUN:-25}" "$PROMPT"
          RUNEOF
          chmod +x .scratch/run-claude.sh

          script -qef .scratch/claude-raw.log -c "bash .scratch/run-claude.sh" > /dev/null 2>&1 &
          CLAUDE_PID=$!
          echo "Claude started (PID: $CLAUDE_PID)"

          PREV_LINES=0
          while kill -0 $CLAUDE_PID 2>/dev/null; do
            sleep 15
            [ -f .scratch/claude-raw.log ] || continue
            CURR_LINES=$(wc -l < .scratch/claude-raw.log)
            if [ "$CURR_LINES" -gt "$PREV_LINES" ]; then
              CHUNK=$(sed -n "$((PREV_LINES + 1)),${CURR_LINES}p" .scratch/claude-raw.log \
                | python3 -u .scratch/stream-filter.py)
              echo "$CHUNK"

              # Stream to Dispatch terminal viewer
              if [ -n "$CHUNK" ] && [ -n "$DISPATCH_API_URL" ] && [ -n "$DISPATCH_API_KEY" ]; then
                jq -n --arg content "$CHUNK" '{content: $content}' | \
                  curl -sf -X POST "${DISPATCH_API_URL}/api/issues/${INPUT_ISSUE_ID}/terminal" \
                    -H "Authorization: Bearer ${DISPATCH_API_KEY}" \
                    -H "Content-Type: application/json" \
                    -d @- > /dev/null 2>&1 &
              fi

              PREV_LINES=$CURR_LINES
            else
              echo "[$(date -u +%H:%M:%S)] Claude working... ($CURR_LINES lines)"
            fi
          done
          wait $CLAUDE_PID
          CLAUDE_EXIT=$?
          echo "=== Claude exited with code $CLAUDE_EXIT ==="

          FINAL_LINES=$(wc -l < .scratch/claude-raw.log)
          if [ "$FINAL_LINES" -gt "$PREV_LINES" ]; then
            FINAL_CHUNK=$(sed -n "$((PREV_LINES + 1)),${FINAL_LINES}p" .scratch/claude-raw.log \
              | python3 -u .scratch/stream-filter.py)
            echo "$FINAL_CHUNK"
            if [ -n "$FINAL_CHUNK" ] && [ -n "$DISPATCH_API_URL" ] && [ -n "$DISPATCH_API_KEY" ]; then
              jq -n --arg content "$FINAL_CHUNK" '{content: $content}' | \
                curl -sf -X POST "${DISPATCH_API_URL}/api/issues/${INPUT_ISSUE_ID}/terminal" \
                  -H "Authorization: Bearer ${DISPATCH_API_KEY}" \
                  -H "Content-Type: application/json" \
                  -d @- > /dev/null 2>&1 || true
            fi
          fi
          python3 -u .scratch/stream-filter.py < .scratch/claude-raw.log > .scratch/claude-output.log

          # Extract cost data from stream-json result event
          python3 -c "
          import json
          for line in open('.scratch/claude-raw.log'):
              line = line.strip()
              if not line: continue
              try:
                  event = json.loads(line)
                  if event.get('type') == 'result':
                      cost = event.get('total_cost_usd', 0)
                      turns = event.get('num_turns', 0)
                      model = event.get('model', 'unknown')
                      with open('.scratch/claude-cost.json', 'w') as f:
                          json.dump({'cost_usd': cost, 'num_turns': turns, 'model': model}, f)
                      print(f'Cost: \${cost:.4f}, Turns: {turns}, Model: {model}')
              except (json.JSONDecodeError, KeyError): pass
          " 2>/dev/null || echo "Warning: Could not extract cost data"

          exit $CLAUDE_EXIT

          # Ensure plan exists even if Claude didn't create one
          if [ ! -f .scratch/plan.md ]; then
            {
              echo "# Investigation Plan"
              echo ""
              echo "Claude Code did not produce a structured plan. Raw output saved to claude-output.log."
              echo ""
              echo '```'
              tail -100 .scratch/claude-output.log
              echo '```'
            } > .scratch/plan.md
          fi

      - name: Parse run result
        id: run-result
        if: always()
        run: |
          if [ ! -f .scratch/run-result.json ]; then
            echo "outcome=failed" >> "$GITHUB_OUTPUT"
            echo "Agent exited without declaring an outcome" > .scratch/outcome-summary.txt
            echo "pr_needed=false" >> "$GITHUB_OUTPUT"
            echo "changes_made=false" >> "$GITHUB_OUTPUT"
            echo "Run outcome: failed (no run-result.json)"
            exit 0
          fi

          OUTCOME=$(jq -r '.outcome // "failed"' .scratch/run-result.json)
          SUMMARY=$(jq -r '.summary // "No summary provided"' .scratch/run-result.json)
          PR_NEEDED=$(jq -r '.pr_needed // false' .scratch/run-result.json)
          CHANGES_MADE=$(jq -r '.changes_made // false' .scratch/run-result.json)

          case "$OUTCOME" in
            completed|no_changes_needed|blocked|needs_human_decision|investigation_complete|failed) ;;
            *) OUTCOME="failed"; SUMMARY="Invalid outcome: $OUTCOME" ;;
          esac

          echo "outcome=$OUTCOME" >> "$GITHUB_OUTPUT"
          echo "$SUMMARY" > .scratch/outcome-summary.txt
          echo "pr_needed=$PR_NEEDED" >> "$GITHUB_OUTPUT"
          echo "changes_made=$CHANGES_MADE" >> "$GITHUB_OUTPUT"

          echo "Run outcome: $OUTCOME"
          echo "Summary: $SUMMARY"

      - name: Post Plan to Dispatch
        if: always() && env.DISPATCH_API_URL != '' && env.DISPATCH_API_KEY != ''
        env:
          JOB_STATUS: ${{ job.status }}
          OUTCOME: ${{ steps.run-result.outputs.outcome }}
        run: |
          if [ ! -f .scratch/plan.md ]; then
            echo "No plan file found." > .scratch/plan.md
          fi

          if [ "$JOB_STATUS" = "success" ]; then
            # Post the plan for review
            PLAN_PAYLOAD=$(jq -n \
              --arg action "submit" \
              --rawfile content .scratch/plan.md \
              '{action: $action, content: $content}')

            curl -sf -X POST "${DISPATCH_API_URL}/api/issues/${INPUT_ISSUE_ID}/plan" \
              -H "Authorization: Bearer ${DISPATCH_API_KEY}" \
              -H "Content-Type: application/json" \
              -d "$PLAN_PAYLOAD" || echo "Warning: Failed to post plan (non-fatal)"

            SPAWN_STATUS="completed"
          else
            SPAWN_STATUS="failed"
          fi

          # Read cost data if available
          COST_USD="0"
          NUM_TURNS="0"
          MODEL="unknown"
          if [ -f .scratch/claude-cost.json ]; then
            COST_USD=$(jq -r '.cost_usd // 0' .scratch/claude-cost.json)
            NUM_TURNS=$(jq -r '.num_turns // 0' .scratch/claude-cost.json)
            MODEL=$(jq -r '.model // "unknown"' .scratch/claude-cost.json)
          fi

          # Post activity log
          ACTIVITY_PAYLOAD=$(jq -n \
            --arg type "investigation_complete" \
            --rawfile content .scratch/plan.md \
            --arg run_id "$GITHUB_RUN_ID" \
            --arg run_url "$GITHUB_RUN_URL" \
            --arg cost_usd "$COST_USD" \
            --arg num_turns "$NUM_TURNS" \
            --arg model "$MODEL" \
            '{type: $type, content: $content, metadata: {run_id: $run_id, run_url: $run_url, workflow_type: "prd_investigate", cost_usd: $cost_usd, num_turns: $num_turns, model: $model}}')

          curl -sf -X POST "${DISPATCH_API_URL}/api/issues/${INPUT_ISSUE_ID}/activity" \
            -H "Authorization: Bearer ${DISPATCH_API_KEY}" \
            -H "Content-Type: application/json" \
            -d "$ACTIVITY_PAYLOAD" || echo "Warning: Failed to post activity (non-fatal)"

          # Read outcome summary from file
          OUTCOME_SUMMARY=""
          if [ -f .scratch/outcome-summary.txt ]; then
            OUTCOME_SUMMARY=$(cat .scratch/outcome-summary.txt)
          fi

          # Update spawn status with cost data and outcome
          TIMESTAMP=$(date -u +%Y-%m-%dT%H:%M:%SZ)
          STATUS_PAYLOAD=$(jq -n \
            --arg spawn_status "$SPAWN_STATUS" \
            --arg spawn_completed_at "$TIMESTAMP" \
            --arg cost_usd "$COST_USD" \
            --arg num_turns "$NUM_TURNS" \
            --arg model "$MODEL" \
            --arg run_outcome "${OUTCOME:-failed}" \
            --arg outcome_summary "$OUTCOME_SUMMARY" \
            '{spawn_status: $spawn_status, spawn_completed_at: $spawn_completed_at, cost_usd: $cost_usd, num_turns: $num_turns, model: $model, run_outcome: $run_outcome, outcome_summary: $outcome_summary}')

          curl -sf -X PATCH "${DISPATCH_API_URL}/api/issues/${INPUT_ISSUE_ID}" \
            -H "Authorization: Bearer ${DISPATCH_API_KEY}" \
            -H "Content-Type: application/json" \
            -d "$STATUS_PAYLOAD" || echo "Warning: Failed to update spawn status (non-fatal)"

          # Update agent run record via /runs/current
          PROMPT_FILE=".scratch/investigation-prompt.md"
          [ -f "$PROMPT_FILE" ] || PROMPT_FILE=".scratch/prompt.md"
          [ -f "$PROMPT_FILE" ] || echo "" > "$PROMPT_FILE"
          [ -f .scratch/claude-output.log ] || echo "" > .scratch/claude-output.log

          REPORT_FILE=".scratch/plan.md"
          [ -f "$REPORT_FILE" ] || echo "" > "$REPORT_FILE"

          RUN_UPDATE=$(jq -n \
            --arg status "$SPAWN_STATUS" \
            --arg outcome "${OUTCOME:-failed}" \
            --arg outcome_summary "$OUTCOME_SUMMARY" \
            --arg cost_usd "$COST_USD" \
            --arg num_turns "$NUM_TURNS" \
            --arg model "$MODEL" \
            --rawfile prompt_text "$PROMPT_FILE" \
            --rawfile transcript .scratch/claude-output.log \
            --rawfile report_content "$REPORT_FILE" \
            '{status: $status, outcome: $outcome, outcome_summary: $outcome_summary, cost_usd: ($cost_usd | tonumber), num_turns: ($num_turns | tonumber), model: $model, prompt_text: $prompt_text, transcript: $transcript, report_content: $report_content}')

          curl -sf -X PATCH "${DISPATCH_API_URL}/api/issues/${INPUT_ISSUE_ID}/runs/current" \
            -H "Authorization: Bearer ${DISPATCH_API_KEY}" \
            -H "Content-Type: application/json" \
            -d "$RUN_UPDATE" || echo "Warning: Failed to update run record (non-fatal)"

      - name: Upload full agent log
        if: always() && env.DISPATCH_API_URL != '' && env.DISPATCH_API_KEY != ''
        run: |
          LOG_FILE=".scratch/claude-output.log"
          if [ ! -f "$LOG_FILE" ]; then
            echo "No output log found, skipping"
            exit 0
          fi

          FULL_SIZE=$(wc -c < "$LOG_FILE")

          # Truncate to ~500KB to stay within reasonable API limits
          head -c 512000 "$LOG_FILE" > .scratch/full-log-truncated.txt
          if [ "$FULL_SIZE" -gt 512000 ]; then
            echo "" >> .scratch/full-log-truncated.txt
            echo "... [truncated - full log was $(( FULL_SIZE / 1024 ))KB]" >> .scratch/full-log-truncated.txt
          fi

          # Use --rawfile to avoid bash quoting issues with arbitrary log content
          jq -n \
            --arg type "agent_full_log" \
            --rawfile content .scratch/full-log-truncated.txt \
            --arg run_id "$GITHUB_RUN_ID" \
            --arg run_url "$GITHUB_RUN_URL" \
            '{type: $type, content: $content, metadata: {run_id: $run_id, run_url: $run_url, workflow_type: "prd_investigate"}}' \
            > .scratch/full-log-payload.json

          curl -sf -X POST "${DISPATCH_API_URL}/api/issues/${INPUT_ISSUE_ID}/activity" \
            -H "Authorization: Bearer ${DISPATCH_API_KEY}" \
            -H "Content-Type: application/json" \
            -d @.scratch/full-log-payload.json || echo "Warning: Failed to upload full log (non-fatal)"

          echo "Full log uploaded ($(( FULL_SIZE / 1024 ))KB)"

      - name: Report failure
        if: failure() && env.DISPATCH_API_URL != '' && env.DISPATCH_API_KEY != ''
        run: |
          ERROR_TAIL=""
          if [ -f .scratch/claude-output.log ]; then
            ERROR_TAIL=$(tail -20 .scratch/claude-output.log)
          fi

          TIMESTAMP=$(date -u +%Y-%m-%dT%H:%M:%SZ)

          FAILURE_PAYLOAD=$(jq -n \
            --arg type "investigation_failed" \
            --arg content "PRD investigation workflow failed." \
            --arg run_id "$GITHUB_RUN_ID" \
            --arg run_url "$GITHUB_RUN_URL" \
            --arg error_tail "$ERROR_TAIL" \
            '{type: $type, content: $content, metadata: {run_id: $run_id, run_url: $run_url, error_tail: $error_tail}}')

          curl -sf -X POST "${DISPATCH_API_URL}/api/issues/${INPUT_ISSUE_ID}/activity" \
            -H "Authorization: Bearer ${DISPATCH_API_KEY}" \
            -H "Content-Type: application/json" \
            -d "$FAILURE_PAYLOAD" || true

          STATUS_PAYLOAD=$(jq -n \
            --arg spawn_status "failed" \
            --arg spawn_completed_at "$TIMESTAMP" \
            --arg agent_status "idle" \
            '{spawn_status: $spawn_status, spawn_completed_at: $spawn_completed_at, agent_status: $agent_status}')

          curl -sf -X PATCH "${DISPATCH_API_URL}/api/issues/${INPUT_ISSUE_ID}" \
            -H "Authorization: Bearer ${DISPATCH_API_KEY}" \
            -H "Content-Type: application/json" \
            -d "$STATUS_PAYLOAD" || true
